import pandas as pd
import numpy as np
from scipy.stats import chi2_contingency, pearsonr
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import os

# ==========================================
# [ì„¤ì •] ì…ë ¥ íŒŒì¼ (ì—‘ì…€ íŒŒì¼ 1ê°œë§Œ ìˆìœ¼ë©´ ë©ë‹ˆë‹¤)
# ==========================================
INPUT_EXCEL = "2025_í›„ê¸°ê³ _ì‹¬ì¸µì—°êµ¬ë³´ê³ ì„œ.xlsx"
OUTPUT_FILE = "2025_í›„ê¸°ê³ _í†µê³„ì _ì‹¬ì¸µë¶„ì„_ìµœì¢….xlsx"

# [ì¤‘ìš”] ìµœì†Œ í‘œë³¸ ê¸°ì¤€ (ì´ ìˆ«ìë³´ë‹¤ ì ìœ¼ë©´ í†µê³„ ë¶„ì„ì—ì„œ ì œì™¸)
MIN_SAMPLE_SCHOOL = 10  # í•™êµë³„ ìµœì†Œ ë°°ì • ì¸ì›
MIN_SAMPLE_DONG = 10    # ë™ë„¤ë³„ ìµœì†Œ ê±°ì£¼ í•™ìƒ ìˆ˜

def run_advanced_stats_final():
    print("ğŸ”¬ ì—‘ì…€ ì‹œíŠ¸ ê¸°ë°˜ ì‹¬ì¸µ í†µê³„ ì—°êµ¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 1. ë°ì´í„° ë¡œë“œ (ì—‘ì…€ì˜ íŠ¹ì • ì‹œíŠ¸ë¥¼ ì½ì–´ì˜´)
    if not os.path.exists(INPUT_EXCEL):
        print(f"âŒ ì˜¤ë¥˜: '{INPUT_EXCEL}' íŒŒì¼ì´ ê°™ì€ í´ë”ì— ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        # ì—‘ì…€ íŒŒì¼ ë‚´ì˜ ì‹œíŠ¸ ì´ë¦„ì´ ì •í™•í•´ì•¼ í•©ë‹ˆë‹¤. (ì´ì „ ì½”ë“œì—ì„œ ìƒì„±í•œ ì´ë¦„)
        df_school = pd.read_excel(INPUT_EXCEL, sheet_name='ì—°êµ¬1_í•™êµë³„_ì¸ê¸°ë„')
        df_matrix = pd.read_excel(INPUT_EXCEL, sheet_name='ë¶€ë¡_ë™ë„¤_í•™êµ_ì „ì²´ë§¤íŠ¸ë¦­ìŠ¤', index_col=0)
        print("âœ” ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {e}")
        print("   -> íŒŒì¼ì´ ì—´ë ¤ìˆë‹¤ë©´ ë‹«ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    # ---------------------------------------------------------
    # [Pre-Step] ë°ì´í„° ì‹ ë¢°ë„ í•„í„°ë§
    # ---------------------------------------------------------
    print(f"\nğŸ” ë°ì´í„° ì¶©ë¶„ì„± ê²€ì‚¬ (ê¸°ì¤€: í•™êµ {MIN_SAMPLE_SCHOOL}ëª…, ë™ë„¤ {MIN_SAMPLE_DONG}ëª… ì´ìƒ)")
    
    # í•™êµ í•„í„°ë§
    valid_schools = df_school[df_school['ì‹¤ì œë°°ì •ì¸ì›'] >= MIN_SAMPLE_SCHOOL].copy()
    dropped_schools = len(df_school) - len(valid_schools)
    print(f"   - í•™êµ: ì „ì²´ {len(df_school)}ê°œ ì¤‘ {len(valid_schools)}ê°œ ë¶„ì„ í¬í•¨ ({dropped_schools}ê°œ ì œì™¸ë¨)")

    # í–‰ì •ë™ í•„í„°ë§ (ë§¤íŠ¸ë¦­ìŠ¤ì—ì„œ í–‰ í•©ê³„ ê³„ì‚°)
    dong_counts = df_matrix.sum(axis=1)
    valid_dongs_idx = dong_counts[dong_counts >= MIN_SAMPLE_DONG].index
    
    # ë§¤íŠ¸ë¦­ìŠ¤ ì¬êµ¬ì„±
    valid_school_names = valid_schools['ë°°ì •ê³ ë“±í•™êµ'].unique()
    common_schools = [s for s in valid_school_names if s in df_matrix.columns]
    
    filtered_matrix = df_matrix.loc[valid_dongs_idx, common_schools]
    print(f"   - í–‰ì •ë™: ì „ì²´ {len(df_matrix)}ê°œ ì¤‘ {len(valid_dongs_idx)}ê°œ ë¶„ì„ í¬í•¨")

    if len(valid_schools) < 3 or filtered_matrix.empty:
        print("âš  ê²½ê³ : ë¶„ì„í•  ìˆ˜ ìˆëŠ” ìœ íš¨ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤.")
        return

    # ---------------------------------------------------------
    # [ì—°êµ¬ 1] K-Means êµ°ì§‘ ë¶„ì„ (ìœ íš¨ í•™êµ ëŒ€ìƒ)
    # ---------------------------------------------------------
    print("\nğŸ“Š 1. í•™êµ ìœ í˜•í™” (Clustering) - ìœ íš¨ ë°ì´í„°ë§Œ")
    
    features = valid_schools[['ì‹¤ì§ˆê²½ìŸë¥ ', 'ë°°ì •ë§Œì¡±ë„(%)']].fillna(0)
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)
    
    n_clusters = 3 if len(valid_schools) > 10 else 2
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    valid_schools['êµ°ì§‘_Label'] = kmeans.fit_predict(scaled_features)
    
    cluster_summary = valid_schools.groupby('êµ°ì§‘_Label')[['ì‹¤ì§ˆê²½ìŸë¥ ', 'ë°°ì •ë§Œì¡±ë„(%)']].mean().reset_index()
    
    def name_cluster(row):
        comp = row['ì‹¤ì§ˆê²½ìŸë¥ ']
        sat = row['ë°°ì •ë§Œì¡±ë„(%)']
        mean_comp = cluster_summary['ì‹¤ì§ˆê²½ìŸë¥ '].mean()
        mean_sat = cluster_summary['ë°°ì •ë§Œì¡±ë„(%)'].mean()
        
        if comp > mean_comp and sat < mean_sat: return "ìœ í˜•A: ê³ ê²½ìŸ_ì•„ì‰¬ì›€(ê³¼ë°€)"
        elif comp < mean_comp and sat > mean_sat: return "ìœ í˜•B: ì•ˆì •_ë§Œì¡±í˜•(ì§€ì—­)"
        elif sat > 90: return "ìœ í˜•C: ê³ ë§Œì¡±_ì ì •í˜•"
        else: return "ìœ í˜•D: ë³µí•©í˜•"

    cluster_summary['ìœ í˜•_íŠ¹ì„±'] = cluster_summary.apply(name_cluster, axis=1)
    label_map = dict(zip(cluster_summary['êµ°ì§‘_Label'], cluster_summary['ìœ í˜•_íŠ¹ì„±']))
    valid_schools['ë¶„ì„_í•™êµìœ í˜•'] = valid_schools['êµ°ì§‘_Label'].map(label_map)

    # ---------------------------------------------------------
    # [ì—°êµ¬ 2] ì¹´ì´ì œê³± ê²€ì • (ìœ íš¨ ë™ë„¤ x ìœ íš¨ í•™êµ)
    # ---------------------------------------------------------
    print("ğŸ“Š 2. ê±°ì£¼ì§€-ë°°ì •í•™êµ ì¢…ì†ì„± ê²€ì • (Filtered)")
    
    filtered_matrix = filtered_matrix.loc[:, (filtered_matrix != 0).any(axis=0)]
    
    if filtered_matrix.size > 0:
        chi2, p, dof, expected = chi2_contingency(filtered_matrix)
        n = filtered_matrix.sum().sum()
        min_dim = min(filtered_matrix.shape) - 1
        cramer_v = np.sqrt(chi2 / (n * min_dim)) if min_dim > 0 else 0
        chi_msg = "í†µê³„ì  ìœ ì˜í•¨ (ê±°ì£¼ì§€ê°€ ë°°ì •ì— ì˜í–¥ ì¤Œ)" if p < 0.05 else "ìš°ì—°ì¼ ê°€ëŠ¥ì„± ë†’ìŒ"
    else:
        chi2, p, cramer_v, chi_msg = 0, 1, 0, "ë°ì´í„° ë¶€ì¡±"

    chi_result = pd.DataFrame({
        "ë¶„ì„ ëŒ€ìƒ": [f"ë™ë„¤ {len(valid_dongs_idx)}ê°œ x í•™êµ {len(common_schools)}ê°œ"],
        "P-value": [p],
        "ê²°ë¡ ": [chi_msg],
        "ì—°ê´€ì„± ê°•ë„(V)": [cramer_v]
    })

    # ---------------------------------------------------------
    # [ì—°êµ¬ 3] ìƒê´€ê´€ê³„ ë¶„ì„
    # ---------------------------------------------------------
    print("ğŸ“Š 3. ê²½ìŸë¥ -ë§Œì¡±ë„ ìƒê´€ê´€ê³„ (Filtered)")
    
    if len(valid_schools) > 2:
        corr, p_val = pearsonr(valid_schools['ì‹¤ì§ˆê²½ìŸë¥ '], valid_schools['ë°°ì •ë§Œì¡±ë„(%)'])
        corr_msg = "ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„ (ê²½ìŸë¥  ë†’ìœ¼ë©´ ë§Œì¡±ë„ ë‚®ìŒ)" if corr < -0.5 else "ì•½í•œ ìƒê´€ê´€ê³„"
    else:
        corr, p_val, corr_msg = 0, 1, "ë°ì´í„° ë¶€ì¡±"

    corr_result = pd.DataFrame({
        "ë¶„ì„ í•™êµ ìˆ˜": [len(valid_schools)],
        "ìƒê´€ê³„ìˆ˜(r)": [corr],
        "P-value": [p_val],
        "í•´ì„": [corr_msg]
    })

    # ---------------------------------------------------------
    # ê²°ê³¼ ì €ì¥
    # ---------------------------------------------------------
    with pd.ExcelWriter(OUTPUT_FILE, engine='openpyxl') as writer:
        valid_schools.sort_values('êµ°ì§‘_Label').to_excel(writer, sheet_name='1_ìœ í˜•í™”(ì‹ ë¢°ë°ì´í„°)', index=False)
        cluster_summary.to_excel(writer, sheet_name='1_êµ°ì§‘ìš”ì•½', index=False)
        chi_result.to_excel(writer, sheet_name='2_ì¢…ì†ì„±ê²€ì •_ê²°ê³¼', index=False)
        corr_result.to_excel(writer, sheet_name='3_ìƒê´€ê´€ê³„_ê²°ê³¼', index=False)

    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! íŒŒì¼ ìƒì„±ë¨: {OUTPUT_FILE}")

if __name__ == "__main__":
    run_advanced_stats_final()